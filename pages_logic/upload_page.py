import streamlit as st
import pandas as pd
import re
from utils import supabase, PRODUCTS_DICT  # –Ü–º–ø–æ—Ä—Ç—É—î–º–æ —Å–ø—ñ–ª—å–Ω—ñ –¥–∞–Ω—ñ


# --- –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –¥–∞–Ω–∏–º–∏ ---

@st.cache_data(ttl=3600)
def load_data_from_supabase(table_name: str, select_query: str = "*") -> list:
    """
    –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –±—É–¥—å-—è–∫–æ—ó —Ç–∞–±–ª–∏—Ü—ñ Supabase.
    –£–í–ê–ì–ê: –¶—è —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î –ª–∏—à–µ –ø–µ—Ä—à—ñ 1000 –∑–∞–ø–∏—Å—ñ–≤.
    """
    try:
        response = supabase.table(table_name).select(select_query).execute()
        return response.data
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –¥–∞–Ω–∏—Ö –∑ —Ç–∞–±–ª–∏—Ü—ñ '{table_name}': {e}")
        return []


def normalize_address(address: str) -> str:
    """
    –ë—ñ–ª—å—à –Ω–∞–¥—ñ–π–Ω–æ –æ—á–∏—â—É—î —ñ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑—É—î —Ä—è–¥–æ–∫ –∞–¥—Ä–µ—Å–∏.
    –í–∏–¥–∞–ª—è—î –Ω–µ–≤–∏–¥–∏–º—ñ —Å–∏–º–≤–æ–ª–∏, –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ —Ç–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç—å –¥–æ –Ω–∏–∂–Ω—å–æ–≥–æ —Ä–µ–≥—ñ—Å—Ç—Ä—É.
    """
    if not isinstance(address, str):
        address = str(address)

    address = address.replace('\xa0', ' ')
    address = re.sub(r'\s+', ' ', address)
    return address.lower().strip()


def get_golden_address(address: str, golden_map: dict) -> dict:
    """
    –®—É–∫–∞—î –∞–¥—Ä–µ—Å—É —É "–∑–æ–ª–æ—Ç–æ–º—É" —Å–ª–æ–≤–Ω–∏–∫—É. –Ø–∫—â–æ –Ω–µ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å, –ø–æ–≤–µ—Ä—Ç–∞—î –ø–æ—Ä–æ–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è.
    """
    lookup_key = normalize_address(address)
    default_result = {'city': None, 'street': None, 'number': None, 'territory': None}
    return golden_map.get(lookup_key, default_result)


# --- –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏ ---

def show():
    """–í—ñ–¥–æ–±—Ä–∞–∂–∞—î —Å—Ç–æ—Ä—ñ–Ω–∫—É –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö."""
    st.title("üöÄ –Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö")
    st.write(
        "–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –≤–∞—à Excel-—Ñ–∞–π–ª. –ï—Ç–∞–ª–æ–Ω–Ω—ñ –¥–∞–Ω—ñ, —Ä–µ–≥—ñ–æ–Ω–∏ —Ç–∞ –∫–ª—ñ—î–Ω—Ç–∏ –±—É–¥—É—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö Supabase."
    )

    all_regions_data = load_data_from_supabase("region")

    # –£–í–ê–ì–ê: –Ø–∫—â–æ —É –≤–∞—Å > 1000 –∫–ª—ñ—î–Ω—Ç—ñ–≤, —Ç—É—Ç —Ç–µ–∂ –º–æ–∂–µ –∑–Ω–∞–¥–æ–±–∏—Ç–∏—Å—å –ø–æ–≤–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    all_clients_data = load_data_from_supabase("client")
    if all_clients_data:
        client_map = {
            str(row.get("client")).strip(): row.get("new_client")
            for row in all_clients_data
        }
    else:
        st.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–æ–≤—ñ–¥–Ω–∏–∫ –∫–ª—ñ—î–Ω—Ç—ñ–≤. –ó—ñ—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –Ω–µ –±—É–¥–µ –≤–∏–∫–æ–Ω–∞–Ω–æ.")
        client_map = {}

    col1, col2 = st.columns(2)
    with col1:
        uploaded_file = st.file_uploader(
            "1. –í–∏–±–µ—Ä—ñ—Ç—å Excel-—Ñ–∞–π–ª –∑ –∞–¥—Ä–µ—Å–∞–º–∏",
            type=['xlsx', 'xls'],
            key="file_uploader"
        )

    with col2:
        if all_regions_data:
            region_names = [region['name'] for region in all_regions_data]
            selected_region_name = st.selectbox("2. –û–±–µ—Ä—ñ—Ç—å —Ä–µ–≥—ñ–æ–Ω –¥–ª—è –æ–±—Ä–æ–±–∫–∏:", region_names, key="region_selector")
        else:
            st.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å–ø–∏—Å–æ–∫ —Ä–µ–≥—ñ–æ–Ω—ñ–≤.")
            selected_region_name = None

    if st.button("üöÄ –û–ø—Ä–∞—Ü—é–≤–∞—Ç–∏", type="primary", key="process_button"):
        if uploaded_file is not None and selected_region_name is not None:
            try:
                df = pd.read_excel(uploaded_file)
                required_columns = ['–†–µ–≥—ñ–æ–Ω', '–§–∞–∫—Ç.–∞–¥—Ä–µ—Å–∞ –¥–æ—Å—Ç–∞–≤–∫–∏', '–ù–∞–π–º–µ–Ω—É–≤–∞–Ω–Ω—è', '–ö–ª—ñ—î–Ω—Ç']
                if not all(col in df.columns for col in required_columns):
                    st.error(
                        f"–ü–æ–º–∏–ª–∫–∞: –í –æ—Å–Ω–æ–≤–Ω–æ–º—É —Ñ–∞–π–ª—ñ –≤—ñ–¥—Å—É—Ç–Ω—è –æ–¥–Ω–∞ –∑ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫: {', '.join(required_columns)}.")
                else:
                    df_filtered = df[df['–†–µ–≥—ñ–æ–Ω'] == selected_region_name].copy()
                    if df_filtered.empty:
                        st.warning(f"–£ —Ñ–∞–π–ª—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∂–æ–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞ –¥–ª—è —Ä–µ–≥—ñ–æ–Ω—É '{selected_region_name}'.")
                    else:
                        with st.spinner(f"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ '–∑–æ–ª–æ—Ç—ñ' –∞–¥—Ä–µ—Å–∏ –¥–ª—è —Ä–µ–≥—ñ–æ–Ω—É '{selected_region_name}'..."):
                            selected_region_id = next(
                                (r['id'] for r in all_regions_data if r['name'] == selected_region_name), None)
                            if selected_region_id is None:
                                st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ ID –¥–ª—è —Ä–µ–≥—ñ–æ–Ω—É '{selected_region_name}'.")
                                st.stop()

                            all_golden_data = []
                            start_index = 0
                            chunk_size = 1000

                            while True:
                                response = supabase.table("golden_addres").select("*") \
                                    .eq("region_id", selected_region_id) \
                                    .range(start_index, start_index + chunk_size - 1) \
                                    .execute()

                                if not response.data and response.error:
                                    st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ '–∑–æ–ª–æ—Ç–∏—Ö' –∞–¥—Ä–µ—Å: {response.error.message}")
                                    st.stop()

                                all_golden_data.extend(response.data)

                                if len(response.data) < chunk_size:
                                    break

                                start_index += chunk_size

                            filtered_golden_data = all_golden_data

                            golden_map = {
                                normalize_address(row.get("–§–∞–∫—Ç.–∞–¥—Ä–µ—Å–∞ –¥–æ—Å—Ç–∞–≤–∫–∏")): {
                                    'city': row.get("–ú—ñ—Å—Ç–æ"), 'street': row.get("–í—É–ª–∏—Ü—è"),
                                    'number': str(row.get("–ù–æ–º–µ—Ä –±—É–¥–∏–Ω–∫—É")) if row.get(
                                        "–ù–æ–º–µ—Ä –±—É–¥–∏–Ω–∫—É") is not None else None,
                                    'territory': row.get("–¢–µ—Ä–∏—Ç–æ—Ä—ñ—è")
                                } for row in filtered_golden_data if row.get("–§–∞–∫—Ç.–∞–¥—Ä–µ—Å–∞ –¥–æ—Å—Ç–∞–≤–∫–∏")
                            }
                        with st.spinner("‚ú® –ó—ñ—Å—Ç–∞–≤–ª—è—î–º–æ –∞–¥—Ä–µ—Å–∏ —Ç–∞ –∫–ª—ñ—î–Ω—Ç—ñ–≤..."):
                            parsed_addresses = df_filtered['–§–∞–∫—Ç.–∞–¥—Ä–µ—Å–∞ –¥–æ—Å—Ç–∞–≤–∫–∏'].apply(get_golden_address,
                                                                                         golden_map=golden_map)
                            parsed_df = pd.json_normalize(parsed_addresses)
                            parsed_df = parsed_df.rename(
                                columns={'city': 'City', 'street': 'Street', 'number': 'House_Number',
                                         'territory': 'Territory'})
                            df_filtered.reset_index(drop=True, inplace=True)
                            parsed_df.reset_index(drop=True, inplace=True)
                            df_filtered.drop(columns=['–í—É–ª–∏—Ü—è', '–ù–æ–º–µ—Ä –±—É–¥–∏–Ω–∫—É', '–¢–µ—Ä–∏—Ç–æ—Ä—ñ—è', 'Adding'], inplace=True,
                                             errors='ignore')
                            result_df = pd.concat([df_filtered, parsed_df], axis=1)
                            date_match = re.search(r'(\d{4}_\d{2}(_\d{2})?)', uploaded_file.name)
                            result_df['Adding'] = date_match.group(0) if date_match else None
                            if date_match:
                                date_parts = date_match.group(0).split("_")
                                result_df['year'] = date_parts[0]
                                result_df['month'] = date_parts[1]
                                result_df['decade'] = date_parts[2] if len(date_parts) > 2 else None
                            else:
                                result_df['year'] = result_df['month'] = result_df['decade'] = None
                            result_df['Product_Line'] = result_df['–ù–∞–π–º–µ–Ω—É–≤–∞–Ω–Ω—è'].str[3:].map(PRODUCTS_DICT)

                            if client_map:
                                result_df['new_client'] = result_df['–ö–ª—ñ—î–Ω—Ç'].astype(str).str.strip().map(client_map)
                            else:
                                result_df['new_client'] = None

                            st.session_state['result_df'] = result_df
            except Exception as e:
                st.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ñ–∞–π–ª—É: {e}")

    if 'result_df' in st.session_state:
        st.success("–ì–æ—Ç–æ–≤–æ! –î–∞–Ω—ñ —É—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ.")
        result_df = st.session_state['result_df']
        st.dataframe(result_df)
        unmatched_df = result_df[result_df['City'].isna()]
        if not unmatched_df.empty:
            st.subheader("‚ö†Ô∏è –ê–¥—Ä–µ—Å–∏, –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ –≤ –µ—Ç–∞–ª–æ–Ω–Ω–æ–º—É —Å–ø–∏—Å–∫—É")
            st.dataframe(unmatched_df[['–§–∞–∫—Ç.–∞–¥—Ä–µ—Å–∞ –¥–æ—Å—Ç–∞–≤–∫–∏']])
        else:
            st.balloons()
            st.success("üéâ –ß—É–¥–æ–≤–æ! –í—Å—ñ –∞–¥—Ä–µ—Å–∏ –∑ –æ–±—Ä–∞–Ω–æ–≥–æ —Ä–µ–≥—ñ–æ–Ω—É –±—É–ª–∏ –∑–Ω–∞–π–¥–µ–Ω—ñ –≤ –µ—Ç–∞–ª–æ–Ω–Ω–æ–º—É —Å–ø–∏—Å–∫—É.")

        unmatched_clients_df = result_df[result_df['new_client'].isna() & result_df['–ö–ª—ñ—î–Ω—Ç'].notna()]
        if not unmatched_clients_df.empty:
            st.subheader("‚ö†Ô∏è –ö–ª—ñ—î–Ω—Ç–∏, –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ –≤ –µ—Ç–∞–ª–æ–Ω–Ω–æ–º—É —Å–ø–∏—Å–∫—É")
            st.dataframe(unmatched_clients_df[['–ö–ª—ñ—î–Ω—Ç']].drop_duplicates())

        ### <<< –ó–ú–Ü–ù–ê: –í–Ü–î–ù–û–í–õ–ï–ù–û –õ–û–ì–Ü–ö–£ –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–• >>>
        if st.button("üíæ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ —É Supabase", key="upload_button"):
            with st.spinner("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–æ Supabase..."):
                try:
                    upload_df = result_df.rename(columns={
                        "–î–∏—Å—Ç—Ä–∏–±'—é—Ç–æ—Ä": "distributor", "–†–µ–≥—ñ–æ–Ω": "region", "–ú—ñ—Å—Ç–æ": "city_xls",
                        "–Ñ–î–†–ü–û–£": "edrpou", "–ö–ª—ñ—î–Ω—Ç": "client", "–Æ—Ä. –∞–¥—Ä–µ—Å–∞ –∫–ª—ñ—î–Ω—Ç–∞": "client_legal_address",
                        "–§–∞–∫—Ç.–∞–¥—Ä–µ—Å–∞ –¥–æ—Å—Ç–∞–≤–∫–∏": "delivery_address", "–ù–∞–π–º–µ–Ω—É–≤–∞–Ω–Ω—è": "product_name",
                        "–ö—ñ–ª—å–∫—ñ—Å—Ç—å": "quantity", "Adding": "adding", "City": "city",
                        "Street": "street", "House_Number": "house_number", "Territory": "territory",
                        "Product_Line": "product_line", "year": "year", "month": "month", "decade": "decade",
                        "new_client": "new_client"
                    })

                    columns_to_upload = [
                        "distributor", "region", "city_xls", "edrpou", "client",
                        "client_legal_address", "delivery_address", "product_name",
                        "quantity", "adding", "city", "street", "house_number",
                        "territory", "product_line", "year", "month", "decade", "new_client"
                    ]

                    final_upload_df = upload_df[[col for col in columns_to_upload if col in upload_df.columns]]
                    # –ó–∞–º—ñ–Ω—é—î–º–æ NaN –Ω–∞ None, —â–æ —î –µ–∫–≤—ñ–≤–∞–ª–µ–Ω—Ç–æ–º NULL –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö
                    final_upload_df = final_upload_df.where(pd.notna(final_upload_df), None)
                    data_to_insert = final_upload_df.to_dict(orient='records')

                    # –í–∏–∫–æ–Ω—É—î–º–æ –≤—Å—Ç–∞–≤–∫—É –¥–∞–Ω–∏—Ö
                    response = supabase.table("sales_data").insert(data_to_insert).execute()

                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ Supabase
                    if response.data:
                        st.success(f"‚úÖ –î–∞–Ω—ñ —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ. –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(response.data)} —Ä—è–¥–∫—ñ–≤.")
                    else:
                        # –Ø–∫—â–æ —î –ø–æ–º–∏–ª–∫–∞, –ø–æ–∫–∞–∑—É—î–º–æ —ó—ó
                        st.error(
                            f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ: {response.error.message if response.error else '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞, –¥–∞–Ω—ñ –Ω–µ –±—É–ª–∏ –≤—Å—Ç–∞–≤–ª–µ–Ω—ñ.'}")
                except Exception as e:
                    st.error(f"–°—Ç–∞–ª–∞—Å—è –∫—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø—ñ–¥–≥–æ—Ç–æ–≤—Ü—ñ –∞–±–æ –≤—Å—Ç–∞–≤—Ü—ñ –¥–∞–Ω–∏—Ö: {e}")
